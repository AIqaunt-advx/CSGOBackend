#!/usr/bin/env python3
"""é¢„æµ‹è¯·æ±‚å·¥å…· - è·å–æ•°æ®å¹¶å‘é€åˆ°é¢„æµ‹APIè¿›è¡Œåˆ†æ"""

import argparse
import json
import os
import sys
from datetime import datetime

import requests

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

try:
    from config import settings
    from tools.llm_test_cli import QuickDataRetriever, format_for_llm
except ImportError as e:
    print(f"âŒ å¯¼å…¥æ¨¡å—å¤±è´¥: {e}", file=sys.stderr)
    print("è¯·ç¡®ä¿åœ¨é¡¹ç›®æ ¹ç›®å½•è¿è¡Œ", file=sys.stderr)
    sys.exit(1)


class PredictRequestTool:
    def __init__(self):
        """åˆå§‹åŒ–é¢„æµ‹è¯·æ±‚å·¥å…·"""
        self.predict_url = settings.PREDICT_API_URL
        self.timeout = 30

    def create_analysis_prompt(self, data: dict, analysis_type: str = "trend") -> str:
        """åˆ›å»ºåˆ†ææç¤ºè¯"""
        prompts = {
            "trend": """
è¯·åˆ†æä»¥ä¸‹CSGOå¸‚åœºæ•°æ®çš„è¶‹åŠ¿ï¼š

æ•°æ®ç»Ÿè®¡ï¼š
- æ•°æ®æ¡æ•°: {count}
- ä»·æ ¼èŒƒå›´: {price_min:.2f} - {price_max:.2f}
- å¹³å‡ä»·æ ¼: {avg_price:.2f}
- æ•°é‡èŒƒå›´: {qty_min} - {qty_max}
- å¹³å‡æ•°é‡: {avg_qty:.1f}
- æ—¶é—´èŒƒå›´: {time_earliest} åˆ° {time_latest}

è¯¦ç»†æ•°æ®ï¼š
{data_json}

è¯·åˆ†æï¼š
1. ä»·æ ¼è¶‹åŠ¿å’Œæ³¢åŠ¨æƒ…å†µ
2. ä¾›éœ€å…³ç³»å˜åŒ–
3. äº¤æ˜“æ´»è·ƒåº¦
4. å¸‚åœºé¢„æµ‹å»ºè®®

è¯·ç”¨ä¸­æ–‡å›ç­”ï¼Œå¹¶æä¾›å…·ä½“çš„æ•°æ®æ”¯æ’‘ã€‚
""",
            "prediction": """
åŸºäºä»¥ä¸‹CSGOå¸‚åœºæ•°æ®ï¼Œè¯·è¿›è¡Œä»·æ ¼é¢„æµ‹åˆ†æï¼š

{data_json}

è¯·åˆ†æï¼š
1. çŸ­æœŸä»·æ ¼èµ°åŠ¿é¢„æµ‹ï¼ˆ1-3å¤©ï¼‰
2. å½±å“ä»·æ ¼çš„å…³é”®å› ç´ 
3. ä¹°å…¥/å–å‡ºå»ºè®®
4. é£é™©è¯„ä¼°

è¯·æä¾›å…·ä½“çš„ä»·æ ¼åŒºé—´é¢„æµ‹å’Œç½®ä¿¡åº¦ã€‚
""",
            "summary": """
è¯·æ€»ç»“ä»¥ä¸‹CSGOå¸‚åœºæ•°æ®çš„å…³é”®ä¿¡æ¯ï¼š

{data_json}

è¯·æä¾›ï¼š
1. å¸‚åœºç°çŠ¶æ¦‚è¿°
2. å…³é”®æ•°æ®æŒ‡æ ‡
3. å¼‚å¸¸æƒ…å†µè¯†åˆ«
4. ç®€è¦ç»“è®º

è¯·ä¿æŒç®€æ´æ˜äº†ã€‚
"""
        }

        template = prompts.get(analysis_type, prompts["trend"])

        # æ ¼å¼åŒ–æ•°æ®
        stats = data.get("statistics", {})
        time_range = data.get("time_range", {})

        return template.format(
            count=data.get("count", 0),
            price_min=stats.get("price_range", [0, 0])[0],
            price_max=stats.get("price_range", [0, 0])[1],
            avg_price=stats.get("avg_price", 0),
            qty_min=stats.get("quantity_range", [0, 0])[0],
            qty_max=stats.get("quantity_range", [0, 0])[1],
            avg_qty=stats.get("avg_quantity", 0),
            time_earliest=time_range.get("earliest", "æœªçŸ¥"),
            time_latest=time_range.get("latest", "æœªçŸ¥"),
            data_json=json.dumps(
                data["data"][:10], indent=2, ensure_ascii=False)  # åªæ˜¾ç¤ºå‰10æ¡
        )

    def send_request(self, prompt: str) -> dict:
        """å‘é€LLMè¯·æ±‚"""
        try:
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {self.api_key}"
            }

            payload = {
                "model": self.model,
                "messages": [
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                "max_tokens": self.max_tokens,
                "temperature": self.temperature
            }

            response = requests.post(
                f"{self.base_url}/chat/completions",
                headers=headers,
                json=payload,
                timeout=self.timeout
            )

            response.raise_for_status()
            return response.json()

        except requests.exceptions.RequestException as e:
            return {"error": f"è¯·æ±‚å¤±è´¥: {e}"}
        except Exception as e:
            return {"error": f"å¤„ç†å¤±è´¥: {e}"}

    def analyze_data(self, data: dict, analysis_type: str = "trend") -> dict:
        """åˆ†ææ•°æ®"""
        if not data.get("data"):
            return {"error": "æ²¡æœ‰å¯åˆ†æçš„æ•°æ®"}

        # åˆ›å»ºæç¤ºè¯
        prompt = self.create_analysis_prompt(data, analysis_type)

        # å‘é€è¯·æ±‚
        result = self.send_request(prompt)

        return {
            "analysis_type": analysis_type,
            "data_summary": {
                "count": data.get("count", 0),
                "time_range": data.get("time_range", {}),
                "statistics": data.get("statistics", {})
            },
            "llm_response": result,
            "timestamp": datetime.now().isoformat()
        }


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='LLMæ•°æ®åˆ†æå·¥å…·')
    parser.add_argument('--method', '-m', choices=['sample', 'latest', 'hours', 'price'],
                        default='latest', help='æ•°æ®è·å–æ–¹æ³•')
    parser.add_argument('--limit', '-l', type=int, default=20, help='è·å–æ•°é‡é™åˆ¶')
    parser.add_argument('--hours', type=int, default=7, help='å°æ—¶æ•° (ç”¨äºhoursæ–¹æ³•)')
    parser.add_argument('--min-price', type=float, help='æœ€å°ä»·æ ¼ (ç”¨äºpriceæ–¹æ³•)')
    parser.add_argument('--max-price', type=float, help='æœ€å¤§ä»·æ ¼ (ç”¨äºpriceæ–¹æ³•)')
    parser.add_argument('--analysis', '-a', choices=['trend', 'prediction', 'summary'],
                        default='trend', help='åˆ†æç±»å‹')
    parser.add_argument('--output', '-o', help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--quiet', '-q', action='store_true', help='é™é»˜æ¨¡å¼')

    args = parser.parse_args()

    if not args.quiet:
        print(f"ğŸš€ å¼€å§‹{args.analysis}åˆ†æ...", file=sys.stderr)
        print(f"ğŸ“Š è·å–{args.method}æ•°æ® (é™åˆ¶: {args.limit})", file=sys.stderr)

    # è·å–æ•°æ®
    retriever = QuickDataRetriever()

    try:
        # è·å–åŸå§‹æ•°æ®
        raw_data = retriever.get_data(
            method=args.method,
            limit=args.limit,
            hours=args.hours,
            min_price=args.min_price,
            max_price=args.max_price
        )

        if not raw_data:
            print("âŒ æ²¡æœ‰è·å–åˆ°æ•°æ®", file=sys.stderr)
            sys.exit(1)

        # æ ¼å¼åŒ–æ•°æ®
        formatted_data = format_for_llm(raw_data)

        if not args.quiet:
            print(f"âœ… è·å–åˆ° {formatted_data['count']} æ¡æ•°æ®", file=sys.stderr)
            print(f"ğŸ¤– å‘é€åˆ°LLMè¿›è¡Œ{args.analysis}åˆ†æ...", file=sys.stderr)

        # LLMåˆ†æ
        llm_tool = LLMRequestTool()
        result = llm_tool.analyze_data(formatted_data, args.analysis)

        # è¾“å‡ºç»“æœ
        output_data = json.dumps(result, indent=2, ensure_ascii=False)

        if args.output:
            with open(args.output, 'w', encoding='utf-8') as f:
                f.write(output_data)
            if not args.quiet:
                print(f"ğŸ“ ç»“æœå·²ä¿å­˜åˆ°: {args.output}", file=sys.stderr)
        else:
            print(output_data)

        if not args.quiet:
            print("âœ… åˆ†æå®Œæˆ", file=sys.stderr)

    except KeyboardInterrupt:
        if not args.quiet:
            print("\nğŸ‘‹ ç”¨æˆ·ä¸­æ–­", file=sys.stderr)
    except Exception as e:
        print(f"âŒ æ‰§è¡Œå‡ºé”™: {e}", file=sys.stderr)
        sys.exit(1)
    finally:
        retriever.close()


if __name__ == "__main__":
    main()
